# BlastOff LLM Configuration
SMALL_MODEL_API_KEY=your-small-model-api-key
SMALL_MODEL_BASE_URL=http://api.siliconflow.cn/v1
SMALL_MODEL_NAME=Qwen/Qwen3-8B

LARGE_MODEL_API_KEY=your-large-model-api-key
LARGE_MODEL_BASE_URL=http://api.siliconflow.cn/v1
LARGE_MODEL_NAME=deepseek-ai/DeepSeek-V3
# Set to "false" for models that don't support prefix parameter (e.g., OpenAI GPT models)
LARGE_MODEL_SUPPORTS_PREFIX=true

# Server Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO